1
00:00:01,170 --> 00:00:02,870
大家好

2
00:00:02,870 --> 00:00:06,060
欢迎收看我的深度机器学习辅导课系列视频

3
00:00:06,060 --> 00:00:10,440
这一系列视频的目的是让学习者对机器学习有一个整体的概念

4
00:00:10,440 --> 00:00:13,740
以及它内在的工作原理
我们将通过学习一系列算法(实现这个目的)

5
00:00:13,740 --> 00:00:19,110
我们先看看回归(regression)

6
00:00:19,110 --> 00:00:23,100
然后看看K-近邻算法的分类和支持向量机

7
00:00:23,100 --> 00:00:27,480
然后我们来看看聚类
它包括 flat cluster 和层次聚类

8
00:00:27,480 --> 00:00:30,510
然后就可以开始了解神经网络的深度学习了

9
00:00:30,510 --> 00:00:32,030
 

10
00:00:32,030 --> 00:00:34,540
(上述的)每一个步骤都有对应的我会提到的主要的算法

11
00:00:34,540 --> 00:00:38,660
和应用

12
00:00:38,670 --> 00:00:41,159
然后我们就要开始深入了解它们内在的联系了

13
00:00:41,159 --> 00:00:45,389
了解了这些理论以后就可以更好的理解这些算法了

14
00:00:45,389 --> 00:00:48,899
这些算法大部分都很basic

15
00:00:48,899 --> 00:00:53,280
因为它们需要具备scale海量数据的能力

16
00:00:53,280 --> 00:00:57,059
好了现在说说它的应用

17
00:00:57,120 --> 00:01:00,959
我们将会用到一个像 Scikit-learn 这样的模块

18
00:01:01,060 --> 00:01:05,780
将这些算法应用到现实生活的数据中
就可以真切的看出ML如何处理它期望从人类得到的input

19
00:01:05,780 --> 00:01:09,300
以及我们应该从它们期待什么样子的output

20
00:01:09,420 --> 00:01:12,000
最后 我们将通过在代码中从头开始重新创建这些算法

21
00:01:12,000 --> 00:01:16,770
来深入每个算法的内部工作

22
00:01:16,770 --> 00:01:20,579
所以这个过程之后

23
00:01:20,580 --> 00:01:24,360
我们就可以对这些算法的工作原理有更加全面的认识

24
00:01:24,360 --> 00:01:25,660
这对后期的学习很有帮助

25
00:01:26,160 --> 00:01:28,640
为了有更好的学习效果

26
00:01:28,640 --> 00:01:33,780
我推荐大家最好有 Python 3 的基础

27
00:01:33,780 --> 00:01:36,509
而且我这儿刚好有 Python 3 的教程

28
00:01:36,509 --> 00:01:39,869
以后用 pip 安装 module 的时候可以用来参考和学习

29
00:01:39,869 --> 00:01:41,729
以后用 pip 安装 module 的时候可以用来参考和学习

30
00:01:41,729 --> 00:01:46,020
之后就可以继续学 ML 辣

31
00:01:46,020 --> 00:01:50,789
但是我觉得怎么说也得学10到15个 Python 核心基础的视频才能行

32
00:01:50,789 --> 00:01:54,509
我们将会在教程里覆盖到一些数学相关的内容

33
00:01:54,509 --> 00:01:58,350
数学部分将会被解释和铺垫

34
00:01:58,350 --> 00:01:59,760
所以这个教程对数学的要求不是特别高

35
00:01:59,760 --> 00:02:03,960
【T_T】大部分是关于算法和几何学

36
00:02:03,960 --> 00:02:09,330
机器学习产生于20世纪50年代
差不多半个世纪前

37
00:02:09,330 --> 00:02:15,210
1959年 Arthur Samuel 提出了机器学习的概念

38
00:02:15,210 --> 00:02:20,010
就是给计算机那种不用提前编写好程序

39
00:02:20,010 --> 00:02:22,050
他就可以有自己学习的能力

40
00:02:22,050 --> 00:02:26,160
我觉得机器学习不那么依赖 hard coding

41
00:02:26,160 --> 00:02:30,570
ML 就很好玩

42
00:02:30,570 --> 00:02:34,620
所以当我向那些觉得 ML 是硬核编程的人们解释这个概念的时候

43
00:02:34,620 --> 00:02:36,510
就发现他们都觉得机器学习很 hard-coded

44
00:02:36,510 --> 00:02:40,710
所以当我问他们机器学习怎么样

45
00:02:40,710 --> 00:02:44,730
或者机器学习和传统意义上的学习有什么区别的时候

46
00:02:44,730 --> 00:02:48,990
就会发现他们他们的想法很因缺斯汀

47
00:02:48,990 --> 00:02:52,530
大多数人不知道 ML 这个学科的存在

48
00:02:52,530 --> 00:02:57,840
而且 ML 也不 hard-coded

49
00:02:57,840 --> 00:03:02,730
1963 年 Vladimir Vapnik 整出了一个支持向量机（SVM）的理论

50
00:03:02,730 --> 00:03:06,150
然而20世纪90年代之前 SVM 一直被低估了

51
00:03:06,150 --> 00:03:10,020
20世纪90年代这位老哥离开了苏联

52
00:03:10,020 --> 00:03:13,830
跳槽去了贝尔实验室

53
00:03:13,830 --> 00:03:17,400
就是那个时候他证明了 SVM 在辨认书写笔迹时比神经网络牛逼

54
00:03:17,400 --> 00:03:22,500
就是那个时候他证明了 SVM 在辨认书写笔迹时比神经网络牛逼

55
00:03:22,500 --> 00:03:25,800
反正就是这个方面 SVM 比神经网络腻害

56
00:03:25,800 --> 00:03:30,090
在一段时间里 SVM 算是比较领先的了

57
00:03:30,090 --> 00:03:35,190
直到最近 Google 又开始重视神经网络 
尤其是 deep learning 这个方向

58
00:03:35,190 --> 00:03:39,989
直到最近 Google 又开始重视神经网络 
尤其是 deep learning 这个方向

59
00:03:39,989 --> 00:03:42,209
直到最近 Google 又开始重视神经网络 
尤其是 deep learning 这个方向

60
00:03:42,640 --> 00:03:46,000
但是如果你觉得自己开始了解机器学习太晚了

61
00:03:46,000 --> 00:03:48,020
我就完全不同意了

62
00:03:48,020 --> 00:03:52,190
回忆一下 1995 年那会儿的计算机

63
00:03:52,200 --> 00:03:53,310
回忆一下 1995 年那会儿的计算机

64
00:03:53,310 --> 00:03:57,510
那会儿我们才刚开始把半导体焊在印刷电路板上

65
00:03:57,510 --> 00:04:04,260
【反正就是很不发达】

66
00:04:04,260 --> 00:04:06,480
然后在 20 世纪 90 年代

67
00:04:06,480 --> 00:04:08,730
即使你是一个 PhD student

68
00:04:08,730 --> 00:04:13,769
也很难可以用到一个跑着 SVM 的电脑

69
00:04:13,769 --> 00:04:18,529
也很难可以用到一个跑着 SVM 的电脑

70
00:04:18,630 --> 00:04:23,010
反而是现在 我们生活在很轻松就能用到 GB 或 TB 级数据的 deep learning 神经网络的年代

71
00:04:23,010 --> 00:04:28,169
反而是现在 我们生活在很轻松就能用到 GB 或 TB 级数据的 deep learning 神经网络的年代

72
00:04:28,169 --> 00:04:32,010
你可以随时在 AWS 上用一个 GPU 集群开始你的机器学习之路

73
00:04:32,010 --> 00:04:36,449
租 AWS 也很便宜 一小时几刀吧

74
00:04:36,449 --> 00:04:37,440
然后就可以开始搞事情了

75
00:04:37,440 --> 00:04:42,750
就像我们生活在一个不可思议的时代一样不可思议

76
00:04:42,750 --> 00:04:46,680
因为这是第一次我们真正可以自己训练机器学习

77
00:04:46,680 --> 00:04:50,310
因为这是第一次我们真正可以自己训练机器学习

78
00:04:50,310 --> 00:04:54,930
 

79
00:04:54,930 --> 00:04:59,550
有了 Scikit-learn 这样的工具

80
00:04:59,550 --> 00:05:03,270
就是很傻瓜很好用的工具
把它用于 ML 的学习中

81
00:05:03,270 --> 00:05:06,860
在不弄乱默认参数的情况下可以得到 90% 到 95% 的准确性

82
00:05:06,870 --> 00:05:10,410
你可以从默认参数入手

83
00:05:10,410 --> 00:05:11,550
很疯狂hhhhh

84
00:05:11,550 --> 00:05:15,120
如果你想追求更高的精确度

85
00:05:15,120 --> 00:05:19,080
那么你就得了解 ML 的工作原理
以及怎么调那些参数

86
00:05:19,080 --> 00:05:23,310
假如你给一个无人驾驶汽车写 ML 的程序
它的辨认区别的精确度在 90% 到 95%

87
00:05:23,310 --> 00:05:26,729
比如区分一滴焦油和一个包在毯子里的小孩

88
00:05:28,020 --> 00:05:31,680
这个精确度久不够了
你得达到更高

89
00:05:31,680 --> 00:05:35,700
无论如何

90
00:05:35,700 --> 00:05:39,090
这个系列的教程是给那些对 ML 感兴趣的人准备的

91
00:05:39,090 --> 00:05:43,530
我这儿还有一些 ML 相关的内容可以给你练练手

92
00:05:43,530 --> 00:05:47,750
多用数据练练 进步贼快

93
00:05:47,760 --> 00:05:48,870
多用数据练练 进步贼快

94
00:05:48,870 --> 00:05:52,740
我们的第一个 topic 是关于回归（regression）的

95
00:05:52,740 --> 00:00:00,000
开始看看吧

