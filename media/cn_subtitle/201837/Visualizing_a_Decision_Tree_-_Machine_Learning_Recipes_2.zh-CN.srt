1
00:00:06,550 --> 00:00:09,370
上一集中 我们使用了决策树
作为我们的分类器

2
00:00:09,370 --> 00:00:10,920
今天我们会学习
怎样添加代码来将它可视化

3
00:00:10,920 --> 00:00:13,032
从而看到它是如何在幕后运行的

4
00:00:13,032 --> 00:00:14,490
分类器有很多种

5
00:00:14,490 --> 00:00:16,740
你可能已经听过一些 --
比如神经网络

6
00:00:16,740 --> 00:00:17,869
或是支持向量机

7
00:00:17,870 --> 00:00:20,234
那我们为什么首先用决策树呢？

8
00:00:20,234 --> 00:00:21,900
那是因为决策树有一大特点

9
00:00:21,900 --> 00:00:23,907
它们简单易读 便于理解

10
00:00:23,907 --> 00:00:26,490
实际上 决策树是
为数不多的可解释的分类器

11
00:00:26,490 --> 00:00:29,740
你可以彻底理解为什么这个分类器
做了这样的决定

12
00:00:29,740 --> 00:00:32,193
这在实战中是非常有用的

13
00:00:33,534 --> 00:00:35,550
好的 我来介绍一下我们今天要用的

14
00:00:35,550 --> 00:00:37,080
一个真实的数据集

15
00:00:37,080 --> 00:00:38,670
这个数据集叫做"莺尾花“

16
00:00:38,670 --> 00:00:41,170
“莺尾花”是一个典型的机器学习问题

17
00:00:41,170 --> 00:00:43,520
在这个问题中
我们想要用不同的测量标准

18
00:00:43,520 --> 00:00:45,180
例如花瓣的长度和宽度

19
00:00:45,180 --> 00:00:46,980
来辨别我们有哪种莺尾花

20
00:00:46,980 --> 00:00:48,260
这个数据集里

21
00:00:48,260 --> 00:00:51,190
我们有三种不同的莺尾花

22
00:00:51,190 --> 00:00:53,965
山莺尾、变色莺尾和青龙莺尾

23
00:00:53,966 --> 00:00:57,520
下拉页面 你会看到
每种花有 50 个样本

24
00:00:57,520 --> 00:01:00,025
所以一共有 150 个样本

25
00:01:00,025 --> 00:01:03,640
注意 每个样本由四个特征来描述

26
00:01:03,640 --> 00:01:06,670
分别是萼片和花瓣的长和宽

27
00:01:06,670 --> 00:01:08,730
就像在“苹果和橘子”问题中一样

28
00:01:08,730 --> 00:01:11,070
表格前四列是这四个特征

29
00:01:11,070 --> 00:01:12,940
而表格最后一列显示标签

30
00:01:12,940 --> 00:01:15,390
就是本行莺尾花样本的种类

31
00:01:15,390 --> 00:01:18,317
我们的目标是用这个数据集
来训练我们的分类器

32
00:01:18,317 --> 00:01:20,690
然后我们就可以用分类器来判断

33
00:01:20,690 --> 00:01:24,496
任意一个新样本
是什么种类的莺尾花了

34
00:01:25,140 --> 00:01:27,960
学习如何使用已有的数据集是很有用的

35
00:01:27,960 --> 00:01:29,979
所以让我们来练习
把“莺尾花”导入到 Scikit-learn 中

36
00:01:29,980 --> 00:01:32,340
来看看它的代码形式是什么样的

37
00:01:32,340 --> 00:01:35,780
Scikit 便利地为我们提供
一系列的样本数据集

38
00:01:35,780 --> 00:01:39,760
包括“莺尾花”
还有一些导入用的工具

39
00:01:39,760 --> 00:01:42,690
我们可以用屏幕上的代码
来导入"莺尾花”数据集

40
00:01:42,690 --> 00:01:45,370
数据集包括维基百科的两张表格

41
00:01:45,370 --> 00:01:47,230
还有一些元数据

42
00:01:47,230 --> 00:01:49,630
元数据包括特征的名字

43
00:01:49,630 --> 00:01:52,160
还有不同种类的花的名字

44
00:01:52,430 --> 00:01:54,190
而上述的特征和种类

45
00:01:54,190 --> 00:01:56,300
存放在数据变量中

46
00:01:56,300 --> 00:01:58,240
举个例子
如果我输出第一个条目

47
00:01:58,240 --> 00:02:00,920
你会看到这朵花的尺寸

48
00:02:00,920 --> 00:02:02,950
这里的数字索引到特征名

49
00:02:02,950 --> 00:02:05,530
所以第一个值指花萼长度

50
00:02:05,530 --> 00:02:08,440
第二个是花萼宽度 以此类推

51
00:02:09,150 --> 00:02:11,750
目标变量中包括标签

52
00:02:11,750 --> 00:02:14,690
类似地 这些数字索引到目标名

53
00:02:14,690 --> 00:02:16,000
现在来输出第一个样本

54
00:02:16,000 --> 00:02:19,230
标签“0”代表山莺尾

55
00:02:19,230 --> 00:02:21,450
如果你看一下维基百科的表格

56
00:02:21,450 --> 00:02:24,519
你会发现我们刚刚输出了第一行

57
00:02:24,520 --> 00:02:27,967
现在数据和目标变量
都有 150 个条目

58
00:02:27,967 --> 00:02:29,550
你也可以选择进行迭代

59
00:02:29,550 --> 00:02:32,082
来输出整个数据集

60
00:02:32,082 --> 00:02:34,040
现在我们学会了如何使用数据集

61
00:02:34,040 --> 00:02:35,850
现在就可以开始训练分类器了

62
00:02:35,850 --> 00:02:39,299
不过在这之前
我们先要把数据分组

63
00:02:39,300 --> 00:02:41,440
我将把一些样本拿出来

64
00:02:41,440 --> 00:02:43,480
先放在一边备用

65
00:02:43,480 --> 00:02:46,329
我们把这些样本称为测试数据

66
00:02:46,330 --> 00:02:48,780
其余的称为训练数据

67
00:02:48,780 --> 00:02:50,940
稍后我们会用这些

68
00:02:50,940 --> 00:02:53,390
机器从未见过的测试数据

69
00:02:53,390 --> 00:02:55,678
来测试完成训练的分类器有多准确

70
00:02:55,679 --> 00:02:57,470
测试是机器学习实战当中

71
00:02:57,470 --> 00:02:59,261
一个非常重要的部分

72
00:02:59,261 --> 00:03:02,280
我们在之后的视频中会详加解释

73
00:03:02,280 --> 00:03:04,710
现在 我将从每一种花中

74
00:03:04,710 --> 00:03:06,050
拿掉一个样本

75
00:03:06,050 --> 00:03:07,520
正好 数据集的编号方式是

76
00:03:07,520 --> 00:03:10,010
第一朵山莺尾样本的索引是 0

77
00:03:10,010 --> 00:03:13,120
第一朵变色莺尾的索引是 50
以此类推

78
00:03:14,271 --> 00:03:16,320
这里的句法看起来比较复杂

79
00:03:16,320 --> 00:03:21,230
其实效果只是移除了
三个刚才说到的条目

80
00:03:21,230 --> 00:03:24,079
然后我将创造两个新的变量集

81
00:03:24,080 --> 00:03:26,587
一个做训练用 另一个测试用

82
00:03:26,587 --> 00:03:28,420
训练集中会有大部分的数据

83
00:03:28,420 --> 00:03:31,369
而测试集中只有我们刚才移除的三项

84
00:03:31,370 --> 00:03:35,020
就像之前一样
我们可以创建一个决策树分类器

85
00:03:35,020 --> 00:03:37,050
然后用训练集中的数据训练它

86
00:03:40,700 --> 00:03:42,200
在我们将它可视化之前

87
00:03:42,200 --> 00:03:44,959
可以先用决策树
来将测试数据做一个分类

88
00:03:44,960 --> 00:03:47,450
已知每种花有一个样本

89
00:03:47,450 --> 00:03:50,179
那么我们可以输出所有可能的标签

90
00:03:50,180 --> 00:03:52,160
现在来看看决策树是如何判断的

91
00:03:52,160 --> 00:03:54,460
我们向它提供测试样本的特征

92
00:03:54,460 --> 00:03:56,350
就能得到标签

93
00:03:56,350 --> 00:03:59,660
你会看到决策树判断的标签
与测试数据相符

94
00:03:59,660 --> 00:04:01,549
这代表决策树做出了正确的判断

95
00:04:01,550 --> 00:04:04,040
要知道 这是一个非常简单的测试

96
00:04:04,040 --> 00:04:07,940
之后我们会详细解析这其中的步骤

97
00:04:07,940 --> 00:04:09,820
现在 我们先来将这棵决策树可视化

98
00:04:09,820 --> 00:04:11,762
来看看这个分类器是如何工作的

99
00:04:11,762 --> 00:04:15,200
首先 我将复制粘贴
Scikit 教程中的部分代码

100
00:04:15,200 --> 00:04:16,993
因为这些代码是用于可视化的

101
00:04:16,994 --> 00:04:18,410
而不是机器学习中的概念

102
00:04:18,410 --> 00:04:20,380
所以我在这一讲中不多解释

103
00:04:20,380 --> 00:04:22,760
注意我现在要合并
这两个样本中的代码

104
00:04:22,760 --> 00:04:26,330
来制作一个简单易读的 PDF

105
00:04:26,330 --> 00:04:28,440
现在我可以运行脚本并打开 PDF

106
00:04:28,440 --> 00:04:30,120
我们就能看到这棵决策树了

107
00:04:30,120 --> 00:04:33,810
要用它来分类数据的话
你需要从上往下看

108
00:04:33,810 --> 00:04:35,830
每个节点代表一个特征

109
00:04:35,830 --> 00:04:37,503
并向其提出一个“是或不是”问题

110
00:04:37,504 --> 00:04:41,410
比如 这个节点提问花朵宽度
是否小于0.8厘米

111
00:04:41,410 --> 00:04:44,200
如果答案是“是” 往左走

112
00:04:44,200 --> 00:04:46,170
反之 往右走

113
00:04:46,170 --> 00:04:48,590
现在我们要用这棵决策树来分类

114
00:04:48,590 --> 00:04:50,130
我们测试数据中的一个样本

115
00:04:50,130 --> 00:04:53,234
这些是第一朵测试花的特征和标签

116
00:04:53,234 --> 00:04:54,900
记住 你可以在元数据中

117
00:04:54,900 --> 00:04:56,580
找到特征名

118
00:04:56,580 --> 00:04:58,979
我们知道这朵花是山莺尾

119
00:04:58,980 --> 00:05:00,780
那么来看看决策树是如何决定的吧

120
00:05:00,780 --> 00:05:03,289
我放大一下这个窗口
这样看得清楚

121
00:05:03,290 --> 00:05:04,890
决策树问的第一个问题是

122
00:05:04,890 --> 00:05:08,110
“花瓣宽度是否小于0.8厘米？”

123
00:05:08,110 --> 00:05:09,540
这是我们的第四特征

124
00:05:09,540 --> 00:05:11,710
答案是“是” 所以我们往左走

125
00:05:11,710 --> 00:05:14,150
这是 我们已经抵达了一个叶节点

126
00:05:14,150 --> 00:05:15,859
没有其他问题可提了

127
00:05:15,860 --> 00:05:18,490
所以决策树给出的判断是“山莺尾”

128
00:05:18,490 --> 00:05:19,440
它答对了！

129
00:05:19,440 --> 00:05:23,330
注意它的标签是 0
是山莺尾的索引

130
00:05:23,330 --> 00:05:25,930
现在我们来试试第二个测试样本

131
00:05:25,930 --> 00:05:27,320
这是一朵变色莺尾

132
00:05:27,320 --> 00:05:29,330
来看看决策树如何判断

133
00:05:29,330 --> 00:05:31,150
同样地 从树的顶端开始

134
00:05:31,150 --> 00:05:33,750
这一次花朵宽度大于0.8厘米

135
00:05:33,750 --> 00:05:35,840
答案是“否”

136
00:05:35,840 --> 00:05:36,830
所以我们往右走

137
00:05:36,830 --> 00:05:40,506
下一个问题是
“花瓣宽度是否小于1.75？"

138
00:05:40,506 --> 00:05:42,469
它在试着得到一个区间

139
00:05:42,470 --> 00:05:44,210
答案是”是“ 所以往左走

140
00:05:44,210 --> 00:05:47,370
现在它问
“花瓣长度是否小于4.95？”

141
00:05:47,370 --> 00:05:49,120
答案也是“是” 所以再往左走

142
00:05:49,120 --> 00:05:52,820
最后 决策树提问
“花瓣宽度是否小于1.65？”

143
00:05:52,820 --> 00:05:54,300
答案是“是” 往左走

144
00:05:54,300 --> 00:05:56,330
那么现在我们就得到了一个判定：

145
00:05:56,330 --> 00:05:57,599
这是一朵变色莺尾

146
00:05:57,600 --> 00:05:58,760
决策树再次答对了

147
00:05:58,760 --> 00:06:01,200
你可以自己试试最后一个样本

148
00:06:01,200 --> 00:06:03,327
记住 我们使用决策树的方法

149
00:06:03,327 --> 00:06:05,230
跟代码运行的方法相同

150
00:06:05,960 --> 00:06:08,284
这就是快速将决策树可视化的方法

151
00:06:08,285 --> 00:06:09,660
这其中还有很多要学的东西

152
00:06:09,660 --> 00:06:12,720
尤其是从样本中
自动建立决策树的过程

153
00:06:12,720 --> 00:06:14,620
我们在之后的视频中会提到

154
00:06:14,620 --> 00:06:17,020
不过现在 我们先总结一下重点

155
00:06:17,020 --> 00:06:18,780
决策树提出的每一个问题

156
00:06:18,780 --> 00:06:20,263
必须针对某个特征

157
00:06:20,264 --> 00:06:22,250
那就意味着你选的特征越可靠

158
00:06:22,250 --> 00:06:23,630
决策树的准确性就越高

159
00:06:23,630 --> 00:06:25,300
下一集中我们会详细讲

160
00:06:25,300 --> 00:06:27,344
如何选择一个可靠的特征

161
00:06:27,344 --> 00:06:28,240
感谢观看

162
00:06:28,240 --> 00:06:29,510
我们下集再见

