1
00:00:00,000 --> 00:00:01,972
［音乐］

2
00:00:06,375 --> 00:00:07,500
乔什·戈登（Josh Gordon):
嗨，大家好

3
00:00:07,500 --> 00:00:08,484
欢迎回来

4
00:00:08,484 --> 00:00:09,900
在这一集中
我会向大家展示

5
00:00:09,900 --> 00:00:12,880
如何训练图像分类器

6
00:00:12,880 --> 00:00:14,844
只需通过图像目录即可完成

7
00:00:14,844 --> 00:00:17,009
比如说，你想要构建一个分类器

8
00:00:17,010 --> 00:00:19,280
来区分霸王龙

9
00:00:19,280 --> 00:00:21,214
和三角龙的图片

10
00:00:21,214 --> 00:00:22,720
或者你想区分

11
00:00:22,720 --> 00:00:25,490
莫奈或毕加索的画

12
00:00:25,490 --> 00:00:27,320
为了做到以上功能
我们需要使用一个代码实验室

13
00:00:27,320 --> 00:00:29,410
叫做TensorFlow for Poets

14
00:00:29,410 --> 00:00:31,020
这是开始学习

15
00:00:31,020 --> 00:00:34,550
并且做图片分类相关工作一个的好方法

16
00:00:34,550 --> 00:00:36,390
现在有两件事

17
00:00:36,390 --> 00:00:38,590
首先，这个代码实验室是非常高级的

18
00:00:38,590 --> 00:00:40,150
为了训练我们的分类器

19
00:00:40,150 --> 00:00:42,720
我们只需要运行几个脚本

20
00:00:42,720 --> 00:00:44,114
令人印象深刻的是

21
00:00:44,114 --> 00:00:45,570
分类器所创造的

22
00:00:45,570 --> 00:00:49,300
要比我几年前自己写的脚本好

23
00:00:49,300 --> 00:00:51,769
我之后会向你展示代码实验室
在运行状态时是什么样子的

24
00:00:51,770 --> 00:00:53,470
我会添加上下文和背景

25
00:00:53,470 --> 00:00:55,530
来解释为什么它这么好

26
00:00:55,530 --> 00:00:57,270
让我们开始吧

27
00:00:57,270 --> 00:00:59,680
要通过TensorFlow for Poets
训练一个图像分类器

28
00:00:59,680 --> 00:01:03,180
我们只需要提供一样东西
——训练数据

29
00:01:03,180 --> 00:01:06,080
也就是一个有很多图像的图像目录

30
00:01:06,080 --> 00:01:07,350
我的计划是创造一个

31
00:01:07,350 --> 00:01:10,600
可以区分五种不同的花的图片分类器

32
00:01:10,600 --> 00:01:12,869
玫瑰、太阳花等等

33
00:01:12,870 --> 00:01:16,010
这就是我的训练数据

34
00:01:16,010 --> 00:01:17,880
注意我有五个目录

35
00:01:17,880 --> 00:01:20,080
每一种花都有一个目录

36
00:01:20,080 --> 00:01:22,740
在每个目录中都有很多的图片

37
00:01:22,740 --> 00:01:24,520
我们用花来举例的原因是

38
00:01:24,520 --> 00:01:26,850
我们在编码实验室中提供了这组数据

39
00:01:26,850 --> 00:01:29,210
因此你可以很快上手

40
00:01:29,210 --> 00:01:30,679
如果你想使用你自己的图片

41
00:01:30,680 --> 00:01:34,050
关于恐龙的图片或者名画
你只需要创建一个目录

42
00:01:34,050 --> 00:01:36,039
把从网上找到的图片放在相应的目录中

43
00:01:36,040 --> 00:01:39,376
每一个目录中都需要大约一百张图片

44
00:01:39,376 --> 00:01:41,160
我们有了训练数据后

45
00:01:41,160 --> 00:01:43,240
我们就可以开始训练分类器了

46
00:01:43,240 --> 00:01:45,920
我们会使用TensorFlow来做这一步

47
00:01:45,920 --> 00:01:48,700
TensorFlow是一个开源的机器学习库

48
00:01:48,700 --> 00:01:50,510
它会变得特别有用

49
00:01:50,510 --> 00:01:53,916
当它和深度学习机一起使用时

50
00:01:53,916 --> 00:01:56,289
深度学习最近几年发展迅猛

51
00:01:56,290 --> 00:01:59,830
尤其在图像分类领域

52
00:01:59,830 --> 00:02:01,830
也就是我们今天所要做的事

53
00:02:01,830 --> 00:02:04,240
这就是其中一个原因

54
00:02:04,240 --> 00:02:06,179
在第一集中

55
00:02:06,180 --> 00:02:07,098
我们讨论过

56
00:02:07,098 --> 00:02:09,630
如何区分苹果和橘子的不同

57
00:02:09,630 --> 00:02:11,290
我们发现手动做这个工作是不可能的

58
00:02:11,290 --> 00:02:14,730
因为世界上有太多不同的苹果和橘子

59
00:02:14,730 --> 00:02:15,790
但现在我们也知道

60
00:02:15,790 --> 00:02:18,630
分类器把特征作为输入

61
00:02:18,630 --> 00:02:20,590
我们很难用代码

62
00:02:20,590 --> 00:02:24,027
把有用的信息从图像中提取出来

63
00:02:24,027 --> 00:02:25,859
比如，你不会想去写一个

64
00:02:25,860 --> 00:02:28,850
可以探测一片水果质地的代码

65
00:02:28,850 --> 00:02:31,150
为了解决这个问题
我们使用深度学习

66
00:02:31,150 --> 00:02:32,850
因为在图像处理方面

67
00:02:32,850 --> 00:02:35,470
它有巨大的优势
就是这个

68
00:02:35,470 --> 00:02:38,280
你不用手动提取特征

69
00:02:38,280 --> 00:02:41,750
你可以使用像素图像的特征

70
00:02:41,750 --> 00:02:44,180
分类器会解决其余问题

71
00:02:44,180 --> 00:02:45,930
为了区分我们训练素材的不同

72
00:02:45,930 --> 00:02:48,170
让我们把鸢尾花数据集

73
00:02:48,170 --> 00:02:50,149
和图像目录相比较

74
00:02:50,150 --> 00:02:52,120
在鸢尾花数据集中

75
00:02:52,120 --> 00:02:53,417
每一列都描述花的一个特征

76
00:02:53,417 --> 00:02:56,420
你可以想象我们是手动提取这些特征的

77
00:02:56,420 --> 00:02:58,619
比如通过尺子来量花朵

78
00:02:58,620 --> 00:03:00,850
相比之下，这是我们的训练数据

79
00:03:00,850 --> 00:03:02,710
在TensorFlow for Poets中

80
00:03:02,710 --> 00:03:05,330
这就是一个标记好的图片清单

81
00:03:05,330 --> 00:03:07,420
图片分类器仅仅是一个函数

82
00:03:07,420 --> 00:03:09,040
f(x)=y

83
00:03:09,040 --> 00:03:11,820
在这里，x是一个2D的图像像素矩阵

84
00:03:11,820 --> 00:03:14,170
y是玫瑰标签

85
00:03:14,170 --> 00:03:16,170
当我们在说深度学习时

86
00:03:16,170 --> 00:03:19,440
我们使用的分类器叫做神经网络

87
00:03:19,440 --> 00:03:22,010
高级层面上来讲
这仅仅是另一个分类器

88
00:03:22,010 --> 00:03:24,920
也就是跟上一次记录相比最接近的一次

89
00:03:24,920 --> 00:03:26,359
区别在于神经网络

90
00:03:26,360 --> 00:03:28,640
可以学习很多复杂的函数

91
00:03:28,640 --> 00:03:30,609
在这个编码实验室里

92
00:03:30,610 --> 00:03:33,160
TensorFlow for Poets会在幕后为你

93
00:03:33,160 --> 00:03:35,290
负责准备并训练编码神经网络

94
00:03:35,290 --> 00:03:36,900
这并不意味着TensorFlow的编码

95
00:03:36,900 --> 00:03:39,780
要比我们目前所看到的更难写

96
00:03:39,780 --> 00:03:42,470
事实上，我最喜欢的
写TensorFlow程序的方法

97
00:03:42,470 --> 00:03:44,520
是使用TF Learn

98
00:03:44,520 --> 00:03:47,250
TF Learn是一个高级机器学习库

99
00:03:47,250 --> 00:03:48,960
比TensorFlow高级些

100
00:03:48,960 --> 00:03:51,530
语法类似于scikit-learn

101
00:03:51,530 --> 00:03:54,364
跟我们目前学习的相似

102
00:03:54,364 --> 00:03:55,780
比如说，这是一个编码片段

103
00:03:55,780 --> 00:03:58,450
它告诉你如何引入神经网络

104
00:03:58,450 --> 00:04:01,790
训练它，利用它来对新数据分类

105
00:04:01,790 --> 00:04:05,619
你可以用你已经学得的技能做到这点

106
00:04:05,619 --> 00:04:07,460
如果你想学习更多
（我没打算一语双关的）

107
00:04:07,460 --> 00:04:08,850
关于这方面的知识

108
00:04:08,850 --> 00:04:12,519
我在视频描述里附上了相关链接
你可以自己去看一看

109
00:04:12,520 --> 00:04:14,590
好了，让我们回到TensorFlow for Poets

110
00:04:14,590 --> 00:04:16,209
并且训练我们的分类器

111
00:04:16,209 --> 00:04:18,356
要做这个，我们要先运行这个脚本

112
00:04:18,356 --> 00:04:19,980
在代码实验室里有所有的详细信息

113
00:04:19,980 --> 00:04:21,899
所以我在这里就不再赘述

114
00:04:21,899 --> 00:04:24,140
但我会对两件事交代一下背景

115
00:04:24,140 --> 00:04:26,020
你也许会想知道

116
00:04:26,020 --> 00:04:28,030
首先，脚本大约需要20分钟

117
00:04:28,030 --> 00:04:29,330
来训练分类器

118
00:04:29,330 --> 00:04:31,680
现在你可以问自己
这是很长的一段时间吗？

119
00:04:31,680 --> 00:04:33,710
当然不是很长

120
00:04:33,710 --> 00:04:35,570
事实上，TensorFlow for Poets

121
00:04:35,570 --> 00:04:38,599
并不是从零开始训练分类器

122
00:04:38,600 --> 00:04:41,030
它是从一个现有的

123
00:04:41,030 --> 00:04:42,679
叫做Inception的分类器开始训练的

124
00:04:42,680 --> 00:04:45,820
Inception是谷歌最好的
图像分类器之一

125
00:04:45,820 --> 00:04:47,360
并且它是开源的

126
00:04:47,360 --> 00:04:50,200
在我们的训练数据里有只有几千张图时

127
00:04:50,200 --> 00:04:54,270
Inception已经通过了一千多种类

128
00:04:54,270 --> 00:04:56,490
一百二十万张图片的训练了

129
00:04:56,490 --> 00:04:58,790
训练Inception需要大约两周的时间

130
00:04:58,790 --> 00:05:01,920
在一个有八个绘图处理器的快速电脑上

131
00:05:01,920 --> 00:05:04,970
在TensorFlow for Poets里
我们以Inception为基础

132
00:05:04,970 --> 00:05:07,360
然后使用一个叫做再次训练的功能

133
00:05:07,360 --> 00:05:09,720
来调试 使其更好地分辨我们的图像

134
00:05:09,720 --> 00:05:13,410
也让我们重新定义
Inception之前学习的一些参数

135
00:05:13,410 --> 00:05:15,970
这样我们就可以用很少的训练数据

136
00:05:15,970 --> 00:05:19,510
创建一个高精准度的分类器

137
00:05:19,510 --> 00:05:21,810
现在训练快结束了

138
00:05:21,810 --> 00:05:25,310
当我们有了一个训练好的分类器后
我们就可以测试它了

139
00:05:25,310 --> 00:05:27,660
我会从维基百科上

140
00:05:27,660 --> 00:05:30,100
下载这张玫瑰的图片

141
00:05:30,100 --> 00:05:32,880
使用我们的分类器来预测这是哪一种花

142
00:05:32,880 --> 00:05:34,840
我们可以看到，答案正确

143
00:05:34,840 --> 00:05:36,820
我们可以看到

144
00:05:36,820 --> 00:05:39,370
对可能是其它花的置信分布

145
00:05:39,370 --> 00:05:41,390
请记住，我们的分类器

146
00:05:41,390 --> 00:05:43,599
仅知道我们向它展示的图片

147
00:05:43,600 --> 00:05:45,410
所以如果我们让它分类一个图片

148
00:05:45,410 --> 00:05:47,150
比如罗马角斗场

149
00:05:47,150 --> 00:05:49,849
它一定会说这是一种花

150
00:05:49,850 --> 00:05:52,910
我们只能希望置信区间会很低了

151
00:05:52,910 --> 00:05:55,850
现在让我再说一两点

152
00:05:55,850 --> 00:05:57,630
训练一个图像分类器

153
00:05:57,630 --> 00:06:01,300
是一个多样性和数量的游戏

154
00:06:01,300 --> 00:06:04,950
多样性来说，我们有更多不同玫瑰的图像

155
00:06:04,950 --> 00:06:06,990
预测结果会更准确

156
00:06:06,990 --> 00:06:08,760
比如说，我们的训练数据包含

157
00:06:08,760 --> 00:06:12,400
红，白，黄色的玫瑰

158
00:06:12,400 --> 00:06:14,820
我们也有在不同角度拍摄的照片

159
00:06:14,820 --> 00:06:17,630
比如从上方或者从旁侧

160
00:06:17,630 --> 00:06:20,610
我们也有玫瑰作为前景

161
00:06:20,610 --> 00:06:22,540
或者是背景的图片

162
00:06:22,540 --> 00:06:24,990
数量上来讲，我的意思是
我们的训练数据越多

163
00:06:24,990 --> 00:06:28,320
我们就会创造更好的分类器

164
00:06:28,320 --> 00:06:31,550
在玫瑰文件夹中有几百张照片

165
00:06:31,550 --> 00:06:33,360
这用来再次训练Inception足够了

166
00:06:33,360 --> 00:06:36,010
你可能可以用更少的图片

167
00:06:36,010 --> 00:06:38,480
不过准确度可能会降低

168
00:06:38,480 --> 00:06:39,601
好了，这就是今天我所要讲的内容

169
00:06:39,601 --> 00:06:41,770
下一步，你可能想要了解更多

170
00:06:41,770 --> 00:06:44,370
并试着写你自己的TensorFlow编码

171
00:06:44,370 --> 00:06:47,380
这是一个告诉你如何做的教程链接

172
00:06:47,380 --> 00:06:50,872
你可以使用同一种办法

173
00:06:50,872 --> 00:06:52,410
感谢大家观看

174
00:06:52,410 --> 00:06:53,743
我们下次再见

175
00:06:53,743 --> 00:06:56,070
［音乐］

