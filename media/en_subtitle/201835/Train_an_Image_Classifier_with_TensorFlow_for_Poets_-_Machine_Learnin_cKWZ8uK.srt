1
00:00:00,000 --> 00:00:01,972
[MUSIC PLAYING]

2
00:00:01,972 --> 00:00:06,375


3
00:00:06,375 --> 00:00:07,500
JOSH GORDON: Hey, everyone.

4
00:00:07,500 --> 00:00:08,484
Welcome back.

5
00:00:08,484 --> 00:00:09,900
In this episode,
I'll show you how

6
00:00:09,900 --> 00:00:13,030
to train your own image
classifier starting from just

7
00:00:13,030 --> 00:00:14,844
a directory of images.

8
00:00:14,844 --> 00:00:17,009
For example, say you want
to build a classifier that

9
00:00:17,010 --> 00:00:19,280
can tell the difference
between a picture of a T.

10
00:00:19,280 --> 00:00:21,214
rex and a triceratops.

11
00:00:21,214 --> 00:00:22,880
Or maybe you want to
classify a painting

12
00:00:22,880 --> 00:00:25,490
as being a Monet or Picasso.

13
00:00:25,490 --> 00:00:27,320
To do that, we'll
work with a code lab

14
00:00:27,320 --> 00:00:29,410
called TensorFlow for Poets.

15
00:00:29,410 --> 00:00:31,020
And this is a great
way to get started

16
00:00:31,020 --> 00:00:34,550
learning about and working
with image classification.

17
00:00:34,550 --> 00:00:36,390
Now two things off the bat.

18
00:00:36,390 --> 00:00:38,590
First, this code
lab is high level.

19
00:00:38,590 --> 00:00:40,800
To train our classifier,
we'll basically just need

20
00:00:40,800 --> 00:00:42,720
to run a couple of scripts.

21
00:00:42,720 --> 00:00:45,254
But what's impressive is what
the classifier will create

22
00:00:45,254 --> 00:00:46,919
is better than what
I could have written

23
00:00:46,920 --> 00:00:49,300
myself just a few years ago.

24
00:00:49,300 --> 00:00:51,769
As we go, I'll show you how
the code lab looks in action,

25
00:00:51,770 --> 00:00:53,470
and I'll add context
and background

26
00:00:53,470 --> 00:00:55,530
on why it works so well.

27
00:00:55,530 --> 00:00:57,270
OK, let's get started.

28
00:00:57,270 --> 00:00:59,680
To train an image classifier
with TensorFlow for Poets,

29
00:00:59,680 --> 00:01:03,180
we'll only need to provide
one thing-- training data.

30
00:01:03,180 --> 00:01:06,080
Here that's just
directories full of images.

31
00:01:06,080 --> 00:01:07,820
My plan is to
create a classifier

32
00:01:07,820 --> 00:01:10,600
to tell the difference between
five types of flowers--

33
00:01:10,600 --> 00:01:12,869
roses, sunflowers, and so on.

34
00:01:12,870 --> 00:01:16,010
And here's what my
training data looks like.

35
00:01:16,010 --> 00:01:17,880
Notice that I have
five directories, one

36
00:01:17,880 --> 00:01:20,080
for each type of flower.

37
00:01:20,080 --> 00:01:22,740
Inside each directory
are lots of pictures.

38
00:01:22,740 --> 00:01:24,520
And the reason I'm
working with flowers

39
00:01:24,520 --> 00:01:26,850
is we provided this
data set in the code lab

40
00:01:26,850 --> 00:01:29,210
so you can get
started right away.

41
00:01:29,210 --> 00:01:31,660
If you want to use your own
images, say, for dinosaurs

42
00:01:31,660 --> 00:01:34,050
or paintings, all you need
to do is create a directory

43
00:01:34,050 --> 00:01:36,039
and fill it with
images from the web.

44
00:01:36,040 --> 00:01:39,376
We'll need about 100 images
in each directory to start.

45
00:01:39,376 --> 00:01:42,000
Once we have our training data,
the next thing we'll need to do

46
00:01:42,000 --> 00:01:43,240
is train our classifier.

47
00:01:43,240 --> 00:01:45,920
And for that, we'll
use TensorFlow.

48
00:01:45,920 --> 00:01:48,700
TensorFlow as an open source
machine learning library.

49
00:01:48,700 --> 00:01:50,620
And it's especially
useful for working

50
00:01:50,620 --> 00:01:53,916
with a branch of machine
learning called deep learning.

51
00:01:53,916 --> 00:01:56,289
Deep learning has led to great
results in the last couple

52
00:01:56,290 --> 00:01:59,830
years, especially in domains
like image classification,

53
00:01:59,830 --> 00:02:01,830
which we'll be
working with today.

54
00:02:01,830 --> 00:02:04,240
And here's one reason why.

55
00:02:04,240 --> 00:02:06,179
Recall that way
back in episode one,

56
00:02:06,180 --> 00:02:08,509
we talked about telling the
difference between apples

57
00:02:08,508 --> 00:02:09,630
and oranges.

58
00:02:09,630 --> 00:02:11,290
We saw it's
impossible to do this

59
00:02:11,290 --> 00:02:14,730
by hand because there's too
much variation in the world.

60
00:02:14,730 --> 00:02:17,500
But now we also know that
classifiers take features

61
00:02:17,500 --> 00:02:18,630
as input.

62
00:02:18,630 --> 00:02:20,590
And with images,
it's incredibly hard

63
00:02:20,590 --> 00:02:24,027
to write code to extract
useful features by hand.

64
00:02:24,027 --> 00:02:25,859
For example, you wouldn't
want to write code

65
00:02:25,860 --> 00:02:28,850
to detect the texture
of a piece of fruit.

66
00:02:28,850 --> 00:02:31,150
To get around this,
we use deep learning

67
00:02:31,150 --> 00:02:34,280
because it has a major advantage
when working with images.

68
00:02:34,280 --> 00:02:35,470
And it's this.

69
00:02:35,470 --> 00:02:38,280
You don't need to extract
features manually.

70
00:02:38,280 --> 00:02:41,750
Instead, you can use the raw
pixels of the image's features,

71
00:02:41,750 --> 00:02:44,180
and the classifier
will do the rest.

72
00:02:44,180 --> 00:02:45,930
To see the difference
in our training data

73
00:02:45,930 --> 00:02:48,170
looks, let's compare
the Iris data set

74
00:02:48,170 --> 00:02:50,149
with our directories of images.

75
00:02:50,150 --> 00:02:52,120
In Iris, each
column is a feature

76
00:02:52,120 --> 00:02:53,417
that describes the flower.

77
00:02:53,417 --> 00:02:55,500
And you can imagine we
came up with these features

78
00:02:55,500 --> 00:02:58,870
manually, say, by measuring
the flower with a ruler.

79
00:02:58,870 --> 00:03:00,850
Now by contrast, here's
our training data

80
00:03:00,850 --> 00:03:02,710
in TensorFlow for Poets.

81
00:03:02,710 --> 00:03:05,330
It's just a list
of labeled images.

82
00:03:05,330 --> 00:03:07,420
And again, a classifier
is just a function.

83
00:03:07,420 --> 00:03:09,040
f of x equals y.

84
00:03:09,040 --> 00:03:11,820
Here x is a 2D array of
pixels from the image.

85
00:03:11,820 --> 00:03:14,170
And y is a label like rose.

86
00:03:14,170 --> 00:03:16,170
Now when we're talking
about deep learning,

87
00:03:16,170 --> 00:03:19,440
the classifier we'll be using
is called a neural network.

88
00:03:19,440 --> 00:03:22,010
At a high level, that's just
another type of classifier,

89
00:03:22,010 --> 00:03:24,920
like the nearest neighbor
one wrote last time.

90
00:03:24,920 --> 00:03:26,359
The difference is
a neural network

91
00:03:26,360 --> 00:03:28,640
can learn more
complex functions.

92
00:03:28,640 --> 00:03:30,609
In this code lab,
TensorFlow for Poets

93
00:03:30,610 --> 00:03:33,160
takes care of setting up and
training the neural network

94
00:03:33,160 --> 00:03:35,290
for you behind the scenes.

95
00:03:35,290 --> 00:03:37,579
That doesn't mean that
TensorFlow code is any harder

96
00:03:37,580 --> 00:03:39,780
to write than what
we've seen so far.

97
00:03:39,780 --> 00:03:42,470
In fact, my favorite way of
writing TensorFlow programs

98
00:03:42,470 --> 00:03:44,520
is by using TF Learn.

99
00:03:44,520 --> 00:03:47,250
And TF Learn is a high level
machine learning library

100
00:03:47,250 --> 00:03:48,960
on top of TensorFlow.

101
00:03:48,960 --> 00:03:51,530
And the syntax is
similar to scikit-learn

102
00:03:51,530 --> 00:03:54,364
like we've seen so far.

103
00:03:54,364 --> 00:03:55,780
For example, here's
a code snippet

104
00:03:55,780 --> 00:03:58,450
that shows you how to
import a neural network,

105
00:03:58,450 --> 00:04:01,790
train it, and use it
to classify new data.

106
00:04:01,790 --> 00:04:05,619
And you can do this using the
skills you've already learned.

107
00:04:05,619 --> 00:04:07,410
If you want to learn
more, no pun intended,

108
00:04:07,410 --> 00:04:09,630
about this stuff
right now, I put links

109
00:04:09,630 --> 00:04:12,519
in the description
you can check out.

110
00:04:12,520 --> 00:04:14,590
OK, now let's return
to TensorFlow for Poets

111
00:04:14,590 --> 00:04:16,209
and train our classifier.

112
00:04:16,209 --> 00:04:18,356
To do that, we'll kick
it off with this script.

113
00:04:18,356 --> 00:04:19,980
It's covered in detail
in the code lab,

114
00:04:19,980 --> 00:04:21,899
so I won't say too
much about it here.

115
00:04:21,899 --> 00:04:24,140
But I will give you
context on two more things

116
00:04:24,140 --> 00:04:26,020
you might want to know about.

117
00:04:26,020 --> 00:04:28,030
First, the script
takes about 20 minutes

118
00:04:28,030 --> 00:04:29,330
to train the classifier.

119
00:04:29,330 --> 00:04:31,680
Now ask yourself,
is that a long time?

120
00:04:31,680 --> 00:04:33,710
The answer turns out to be no.

121
00:04:33,710 --> 00:04:35,570
Under the hood,
TensorFlow for Poets

122
00:04:35,570 --> 00:04:38,599
isn't actually training a
classifier from scratch.

123
00:04:38,600 --> 00:04:41,530
Instead, it's starting with
an existing classifier called

124
00:04:41,530 --> 00:04:42,679
Inception.

125
00:04:42,680 --> 00:04:45,820
And Inception is one of
Google's best image classifiers.

126
00:04:45,820 --> 00:04:47,360
And it's open source.

127
00:04:47,360 --> 00:04:50,200
Whereas we have just a couple
thousand images in our training

128
00:04:50,200 --> 00:04:54,270
data, Inception was trained
on 1.2 million images

129
00:04:54,270 --> 00:04:56,490
from 1,000 different categories.

130
00:04:56,490 --> 00:05:00,160
Training Inception took about
two weeks on a fast desktop

131
00:05:00,160 --> 00:05:01,920
with eight GPUs.

132
00:05:01,920 --> 00:05:04,970
In TensorFlow for Poets,
we'll begin with Inception

133
00:05:04,970 --> 00:05:07,360
and then use a technique
called retraining

134
00:05:07,360 --> 00:05:09,720
to adjust it to work
with our images.

135
00:05:09,720 --> 00:05:12,270
This lets us re-use some
of the parameters Inception

136
00:05:12,270 --> 00:05:15,969
has previously learned so we
can create a new high accuracy

137
00:05:15,970 --> 00:05:19,510
classifier with far
less training data.

138
00:05:19,510 --> 00:05:21,810
I'll fast forward til
our training finishes.

139
00:05:21,810 --> 00:05:25,310
And once we have a trained
classifier, we can try it out.

140
00:05:25,310 --> 00:05:27,660
To do that, I'll download
this image of a rose

141
00:05:27,660 --> 00:05:30,100
from Wikimedia Commons
and use our classifier

142
00:05:30,100 --> 00:05:32,880
to predict what type
of flower it is.

143
00:05:32,880 --> 00:05:34,840
As we can see, it gets it right.

144
00:05:34,840 --> 00:05:36,820
And we can see the
confidence distribution

145
00:05:36,820 --> 00:05:39,370
for the other types
of flowers as well.

146
00:05:39,370 --> 00:05:41,390
Now keep in mind
our classifier only

147
00:05:41,390 --> 00:05:43,599
knows about the training
data we've shown it.

148
00:05:43,600 --> 00:05:45,410
So if we ask it to
classify an image,

149
00:05:45,410 --> 00:05:48,020
say, of the Roman
Colosseum, it must predict

150
00:05:48,020 --> 00:05:49,849
that it's a type of flower.

151
00:05:49,850 --> 00:05:52,910
Hopefully, though, the
confidence will be low.

152
00:05:52,910 --> 00:05:55,850
Now let me give you one or
two more closing thoughts.

153
00:05:55,850 --> 00:05:57,630
To train a good
image classifier,

154
00:05:57,630 --> 00:06:01,300
the name of the game is
diversity and quantity.

155
00:06:01,300 --> 00:06:03,120
By diversity, I
mean the more images

156
00:06:03,120 --> 00:06:06,990
of different types of roses we
have, the better off we'll be.

157
00:06:06,990 --> 00:06:08,760
For example, our
training data includes

158
00:06:08,760 --> 00:06:12,400
pictures of red, white,
and yellow roses.

159
00:06:12,400 --> 00:06:14,820
We also have pictures
taken at different angles,

160
00:06:14,820 --> 00:06:17,630
say, from above or to the side.

161
00:06:17,630 --> 00:06:20,610
And we've included pictures
of roses in the foreground

162
00:06:20,610 --> 00:06:22,540
as well as the background.

163
00:06:22,540 --> 00:06:24,990
Now by quantity, I mean the
more training data we have,

164
00:06:24,990 --> 00:06:28,320
the better a classifier
we're likely to create.

165
00:06:28,320 --> 00:06:31,550
There are several hundred
images inside the roses folder.

166
00:06:31,550 --> 00:06:33,360
That's enough to
retrain Inception.

167
00:06:33,360 --> 00:06:36,010
And you can probably get
away with even fewer images,

168
00:06:36,010 --> 00:06:38,480
though your accuracy
might decrease.

169
00:06:38,480 --> 00:06:39,601
OK, that's it for now.

170
00:06:39,601 --> 00:06:41,100
As a next step,
you'll probably want

171
00:06:41,100 --> 00:06:44,370
to dig deeper and try writing
your own TensorFlow code.

172
00:06:44,370 --> 00:06:47,380
Here's a link to a tutorial that
will show you how to do that.

173
00:06:47,380 --> 00:06:50,702
And you can use exactly the
same technology we saw here.

174
00:06:50,702 --> 00:06:52,410
As always, thanks very
much for watching.

175
00:06:52,410 --> 00:06:53,743
And I'll see you guys next time.

176
00:06:53,743 --> 00:06:56,070
[MUSIC PLAYING]

177
00:06:56,070 --> 00:07:06,665


