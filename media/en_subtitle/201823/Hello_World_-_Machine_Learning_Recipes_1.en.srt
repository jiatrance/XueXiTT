1
00:00:00,000 --> 00:00:02,886
[MUSIC PLAYING]

2
00:00:02,886 --> 00:00:06,726


3
00:00:06,726 --> 00:00:08,100
Six lines of code
is all it takes

4
00:00:08,100 --> 00:00:10,129
to write your first
Machine Learning program.

5
00:00:10,130 --> 00:00:11,671
My name's Josh
Gordon, and today I'll

6
00:00:11,671 --> 00:00:14,373
walk you through writing Hello
World for Machine learning.

7
00:00:14,374 --> 00:00:16,040
In the first few
episodes of the series,

8
00:00:16,040 --> 00:00:17,997
we'll teach you how to
get started with Machine

9
00:00:17,998 --> 00:00:19,080
Learning from scratch.

10
00:00:19,080 --> 00:00:21,560
To do that, we'll work with
two open source libraries,

11
00:00:21,560 --> 00:00:23,706
scikit-learn and TensorFlow.

12
00:00:23,706 --> 00:00:25,330
We'll see scikit in
action in a minute.

13
00:00:25,330 --> 00:00:27,830
But first, let's talk quickly
about what Machine Learning is

14
00:00:27,830 --> 00:00:29,240
and why it's important.

15
00:00:29,240 --> 00:00:31,197
You can think of Machine
Learning as a subfield

16
00:00:31,198 --> 00:00:32,409
of artificial intelligence.

17
00:00:32,409 --> 00:00:35,610
Early AI programs typically
excelled at just one thing.

18
00:00:35,610 --> 00:00:37,240
For example, Deep
Blue could play chess

19
00:00:37,240 --> 00:00:40,150
at a championship level,
but that's all it could do.

20
00:00:40,150 --> 00:00:41,780
Today we want to
write one program that

21
00:00:41,780 --> 00:00:45,340
can solve many problems without
needing to be rewritten.

22
00:00:45,340 --> 00:00:47,460
AlphaGo is a great
example of that.

23
00:00:47,460 --> 00:00:50,150
As we speak, it's competing
in the World Go Championship.

24
00:00:50,150 --> 00:00:53,739
But similar software can also
learn to play Atari games.

25
00:00:53,740 --> 00:00:55,956
Machine Learning is what
makes that possible.

26
00:00:55,956 --> 00:00:57,330
It's the study of
algorithms that

27
00:00:57,330 --> 00:00:59,040
learn from examples
and experience

28
00:00:59,040 --> 00:01:00,909
instead of relying
on hard-coded rules.

29
00:01:00,909 --> 00:01:02,199
So that's the state-of-the-art.

30
00:01:02,200 --> 00:01:03,750
But here's a much
simpler example

31
00:01:03,750 --> 00:01:05,632
we'll start coding up today.

32
00:01:05,632 --> 00:01:07,590
I'll give you a problem
that sounds easy but is

33
00:01:07,590 --> 00:01:09,662
impossible to solve
without Machine Learning.

34
00:01:09,662 --> 00:01:11,370
Can you write code to
tell the difference

35
00:01:11,370 --> 00:01:12,774
between an apple and an orange?

36
00:01:12,774 --> 00:01:15,190
Imagine I asked you to write
a program that takes an image

37
00:01:15,190 --> 00:01:17,070
file as input,
does some analysis,

38
00:01:17,070 --> 00:01:18,649
and outputs the types of fruit.

39
00:01:18,650 --> 00:01:20,040
How can you solve this?

40
00:01:20,040 --> 00:01:22,526
You'd have to start by
writing lots of manual rules.

41
00:01:22,526 --> 00:01:23,899
For example, you
could write code

42
00:01:23,900 --> 00:01:26,316
to count how many orange pixels
there are and compare that

43
00:01:26,316 --> 00:01:27,570
to the number of green ones.

44
00:01:27,570 --> 00:01:30,919
The ratio should give you a
hint about the type of fruit.

45
00:01:30,920 --> 00:01:33,044
That works fine for
simple images like these.

46
00:01:33,044 --> 00:01:34,710
But as you dive deeper
into the problem,

47
00:01:34,710 --> 00:01:37,100
you'll find the real world
is messy, and the rules you

48
00:01:37,100 --> 00:01:38,649
write start to break.

49
00:01:38,650 --> 00:01:41,180
How would you write code to
handle black-and-white photos

50
00:01:41,180 --> 00:01:44,480
or images with no apples
or oranges in them at all?

51
00:01:44,480 --> 00:01:46,360
In fact, for just about
any rule you write,

52
00:01:46,360 --> 00:01:48,790
I can find an image
where it won't work.

53
00:01:48,790 --> 00:01:50,310
You'd need to write
tons of rules,

54
00:01:50,310 --> 00:01:52,518
and that's just to tell the
difference between apples

55
00:01:52,518 --> 00:01:53,690
and oranges.

56
00:01:53,690 --> 00:01:57,390
If I gave you a new problem, you
need to start all over again.

57
00:01:57,390 --> 00:01:59,080
Clearly, we need
something better.

58
00:01:59,080 --> 00:02:00,760
To solve this, we
need an algorithm

59
00:02:00,760 --> 00:02:02,480
that can figure out
the rules for us,

60
00:02:02,480 --> 00:02:04,600
so we don't have to
write them by hand.

61
00:02:04,600 --> 00:02:07,690
And for that, we're going
to train a classifier.

62
00:02:07,690 --> 00:02:10,359
For now you can think of a
classifier as a function.

63
00:02:10,360 --> 00:02:13,160
It takes some data as input
and assigns a label to it

64
00:02:13,160 --> 00:02:14,282
as output.

65
00:02:14,282 --> 00:02:15,740
For example, I
could have a picture

66
00:02:15,740 --> 00:02:18,236
and want to classify it
as an apple or an orange.

67
00:02:18,236 --> 00:02:20,109
Or I have an email, and
I want to classify it

68
00:02:20,110 --> 00:02:22,040
as spam or not spam.

69
00:02:22,040 --> 00:02:23,690
The technique to
write the classifier

70
00:02:23,690 --> 00:02:26,220
automatically is called
supervised learning.

71
00:02:26,220 --> 00:02:29,320
It begins with examples of
the problem you want to solve.

72
00:02:29,320 --> 00:02:31,620
To code this up, we'll
work with scikit-learn.

73
00:02:31,620 --> 00:02:34,095
Here, I'll download and
install the library.

74
00:02:34,095 --> 00:02:35,970
There are a couple
different ways to do that.

75
00:02:35,970 --> 00:02:38,242
But for me, the easiest
has been to use Anaconda.

76
00:02:38,242 --> 00:02:40,450
This makes it easy to get
all the dependencies set up

77
00:02:40,450 --> 00:02:42,440
and works well cross-platform.

78
00:02:42,440 --> 00:02:44,190
With the magic of
video, I'll fast forward

79
00:02:44,190 --> 00:02:45,776
through downloading
and installing it.

80
00:02:45,776 --> 00:02:47,150
Once it's installed,
you can test

81
00:02:47,150 --> 00:02:48,608
that everything is
working properly

82
00:02:48,608 --> 00:02:51,364
by starting a Python script
and importing SK learn.

83
00:02:51,364 --> 00:02:53,780
Assuming that worked, that's
line one of our program down,

84
00:02:53,780 --> 00:02:56,146
five to go.

85
00:02:56,146 --> 00:02:57,519
To use supervised
learning, we'll

86
00:02:57,520 --> 00:03:00,280
follow a recipe with
a few standard steps.

87
00:03:00,280 --> 00:03:02,340
Step one is to
collect training data.

88
00:03:02,340 --> 00:03:04,790
These are examples of the
problem we want to solve.

89
00:03:04,790 --> 00:03:06,790
For our problem, we're
going to write a function

90
00:03:06,790 --> 00:03:08,001
to classify a piece of fruit.

91
00:03:08,002 --> 00:03:10,210
For starters, it will take
a description of the fruit

92
00:03:10,210 --> 00:03:11,680
as input and
predict whether it's

93
00:03:11,680 --> 00:03:14,350
an apple or an orange as
output, based on features

94
00:03:14,350 --> 00:03:16,310
like its weight and texture.

95
00:03:16,310 --> 00:03:18,160
To collect our
training data, imagine

96
00:03:18,160 --> 00:03:19,310
we head out to an orchard.

97
00:03:19,310 --> 00:03:21,060
We'll look at different
apples and oranges

98
00:03:21,060 --> 00:03:23,627
and write down measurements
that describe them in a table.

99
00:03:23,627 --> 00:03:25,210
In Machine Learning
these measurements

100
00:03:25,210 --> 00:03:26,650
are called features.

101
00:03:26,650 --> 00:03:28,970
To keep things simple,
here we've used just two--

102
00:03:28,970 --> 00:03:31,650
how much each fruit weighs in
grams and its texture, which

103
00:03:31,650 --> 00:03:33,830
can be bumpy or smooth.

104
00:03:33,830 --> 00:03:35,860
A good feature makes
it easy to discriminate

105
00:03:35,860 --> 00:03:37,960
between different
types of fruit.

106
00:03:37,960 --> 00:03:40,210
Each row in our training
data is an example.

107
00:03:40,210 --> 00:03:42,260
It describes one piece of fruit.

108
00:03:42,260 --> 00:03:44,239
The last column is
called the label.

109
00:03:44,240 --> 00:03:46,257
It identifies what type
of fruit is in each row,

110
00:03:46,257 --> 00:03:47,840
and there are just
two possibilities--

111
00:03:47,840 --> 00:03:49,430
apples and oranges.

112
00:03:49,430 --> 00:03:51,560
The whole table is
our training data.

113
00:03:51,560 --> 00:03:53,070
Think of these as
all the examples

114
00:03:53,070 --> 00:03:55,120
we want the classifier
to learn from.

115
00:03:55,120 --> 00:03:57,660
The more training data you
have, the better a classifier

116
00:03:57,660 --> 00:03:59,310
you can create.

117
00:03:59,310 --> 00:04:01,620
Now let's write down our
training data in code.

118
00:04:01,620 --> 00:04:04,150
We'll use two variables--
features and labels.

119
00:04:04,150 --> 00:04:06,060
Features contains the
first two columns,

120
00:04:06,060 --> 00:04:07,887
and labels contains the last.

121
00:04:07,887 --> 00:04:09,470
You can think of
features as the input

122
00:04:09,470 --> 00:04:13,401
to the classifier and labels
as the output we want.

123
00:04:13,401 --> 00:04:15,650
I'm going to change the
variable types of all features

124
00:04:15,650 --> 00:04:18,980
to ints instead of strings,
so I'll use 0 for bumpy and 1

125
00:04:18,980 --> 00:04:19,937
for smooth.

126
00:04:19,937 --> 00:04:22,270
I'll do the same for our
labels, so I'll use 0 for apple

127
00:04:22,270 --> 00:04:23,740
and 1 for orange.

128
00:04:23,740 --> 00:04:26,300
These are lines two and
three in our program.

129
00:04:26,300 --> 00:04:29,160
Step two in our recipes to
use these examples to train

130
00:04:29,160 --> 00:04:30,440
a classifier.

131
00:04:30,440 --> 00:04:32,350
The type of classifier
we'll start with

132
00:04:32,350 --> 00:04:34,030
is called a decision tree.

133
00:04:34,030 --> 00:04:35,450
We'll dive into
the details of how

134
00:04:35,450 --> 00:04:37,110
these work in a future episode.

135
00:04:37,110 --> 00:04:41,270
But for now, it's OK to think of
a classifier as a box of rules.

136
00:04:41,270 --> 00:04:43,880
That's because there are many
different types of classifier,

137
00:04:43,880 --> 00:04:47,740
but the input and output
type is always the same.

138
00:04:47,740 --> 00:04:49,170
I'm going to import the tree.

139
00:04:49,170 --> 00:04:52,000
Then on line four of our script,
we'll create the classifier.

140
00:04:52,000 --> 00:04:54,460
At this point, it's just
an empty box of rules.

141
00:04:54,460 --> 00:04:56,830
It doesn't know anything
about apples and oranges yet.

142
00:04:56,830 --> 00:04:58,870
To train it, we'll need
a learning algorithm.

143
00:04:58,870 --> 00:05:00,307
If a classifier
is a box of rules,

144
00:05:00,307 --> 00:05:02,140
then you can think of
the learning algorithm

145
00:05:02,140 --> 00:05:04,169
as the procedure
that creates them.

146
00:05:04,170 --> 00:05:06,937
It does that by finding
patterns in your training data.

147
00:05:06,937 --> 00:05:09,270
For example, it might notice
oranges tend to weigh more,

148
00:05:09,270 --> 00:05:11,919
so it'll create a rule saying
that the heavier fruit is,

149
00:05:11,920 --> 00:05:14,270
the more likely it
is to be an orange.

150
00:05:14,270 --> 00:05:16,130
In scikit, the
training algorithm

151
00:05:16,130 --> 00:05:19,316
is included in the classifier
object, and it's called Fit.

152
00:05:19,316 --> 00:05:21,900
You can think of Fit as being
a synonym for "find patterns

153
00:05:21,900 --> 00:05:23,135
in data."

154
00:05:23,136 --> 00:05:24,510
We'll get into
the details of how

155
00:05:24,510 --> 00:05:27,039
this happens under the
hood in a future episode.

156
00:05:27,040 --> 00:05:29,100
At this point, we have
a trained classifier.

157
00:05:29,100 --> 00:05:32,860
So let's take it for a spin and
use it to classify a new fruit.

158
00:05:32,860 --> 00:05:36,036
The input to the classifier is
the features for a new example.

159
00:05:36,036 --> 00:05:37,660
Let's say the fruit
we want to classify

160
00:05:37,660 --> 00:05:39,750
is 150 grams and bumpy.

161
00:05:39,750 --> 00:05:43,870
The output will be 0 if it's an
apple or 1 if it's an orange.

162
00:05:43,870 --> 00:05:46,310
Before we hit Enter and see
what the classifier predicts,

163
00:05:46,310 --> 00:05:47,690
let's think for a sec.

164
00:05:47,690 --> 00:05:51,160
If you had to guess, what would
you say the output should be?

165
00:05:51,160 --> 00:05:53,980
To figure that out, compare
this fruit to our training data.

166
00:05:53,980 --> 00:05:55,630
It looks like it's
similar to an orange

167
00:05:55,630 --> 00:05:57,077
because it's heavy and bumpy.

168
00:05:57,077 --> 00:05:59,160
That's what I'd guess
anyway, and if we hit Enter,

169
00:05:59,160 --> 00:06:01,834
it's what our classifier
predicts as well.

170
00:06:01,834 --> 00:06:03,250
If everything
worked for you, then

171
00:06:03,250 --> 00:06:06,050
that's it for your first
Machine Learning program.

172
00:06:06,050 --> 00:06:08,680
You can create a new
classifier for a new problem

173
00:06:08,680 --> 00:06:10,770
just by changing
the training data.

174
00:06:10,770 --> 00:06:13,010
That makes this approach
far more reusable

175
00:06:13,010 --> 00:06:15,101
than writing new rules
for each problem.

176
00:06:15,101 --> 00:06:17,350
Now, you might be wondering
why we described our fruit

177
00:06:17,350 --> 00:06:19,790
using a table of features
instead of using pictures

178
00:06:19,790 --> 00:06:21,760
of the fruit as training data.

179
00:06:21,760 --> 00:06:23,360
Well, you can use
pictures, and we'll

180
00:06:23,360 --> 00:06:25,120
get to that in a future episode.

181
00:06:25,120 --> 00:06:27,280
But, as you'll see later
on, the way we did it here

182
00:06:27,280 --> 00:06:29,001
is more general.

183
00:06:29,002 --> 00:06:30,960
The neat thing is that
programming with Machine

184
00:06:30,960 --> 00:06:32,029
Learning isn't hard.

185
00:06:32,029 --> 00:06:33,820
But to get it right,
you need to understand

186
00:06:33,820 --> 00:06:35,407
a few important concepts.

187
00:06:35,407 --> 00:06:37,990
I'll start walking you through
those in the next few episodes.

188
00:06:37,990 --> 00:06:40,198
Thanks very much for watching,
and I'll see you then.

189
00:06:40,198 --> 00:06:43,849
[MUSIC PLAYING]

190
00:06:43,850 --> 00:06:52,408


